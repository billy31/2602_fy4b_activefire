#!/usr/bin/env python3
"""
train_landsat.py - ç«ç‚¹æ£€æµ‹ç»¼åˆä¼˜åŒ–ç‰ˆï¼ˆå…¨é›†æˆè‡ªåŠ¨æ”¹è¿›ï¼‰
GitHub: https://github.com/billy31/2602_fy4b_activefire

æœ¬æ¬¡æ›´æ–°ï¼ˆä¸»è¦æ”¹åŠ¨ï¼‰:
1. æŸå¤±å‡½æ•°ï¼šFocal + Dice ç»„åˆï¼ˆå¯¹ç±»åˆ«ä¸å¹³è¡¡æ›´é²æ£’ï¼‰ï¼Œæ›¿ä»£åŸå…ˆçº¯Dice
2. æ•°æ®ï¼šæ”¯æŒ --use-all-regions å°† training ä¸‹æ‰€æœ‰åœ°åŒºåˆå¹¶è®­ç»ƒï¼›ä¸¥æ ¼æŒ‰ raw <-> mask_label (å¸¦_voting_) ä¸€ä¸€é…å¯¹
3. é‡‡æ ·ï¼šåŸºäºæ¯ä¸ªæ ·æœ¬çš„ fg_count ä½¿ç”¨ WeightedRandomSampler åšè¿‡é‡‡æ ·ä»¥ç¼“è§£æ ·æœ¬çº§ä¸å¹³è¡¡
4. å¢å¼ºï¼šå¢åŠ éšæœºæ—‹è½¬ã€äº®åº¦æŠ–åŠ¨ã€é«˜æ–¯å™ªå£°ç­‰åŒæ­¥å¢å¼ºï¼Œä¿è¯ image/mask å˜æ¢ä¸€è‡´
5. è®­ç»ƒç¨³å®šæ€§ï¼šå¢åŠ æ¢¯åº¦ç´¯ç§¯ï¼ˆ--accum-stepsï¼‰ï¼Œæ··åˆç²¾åº¦ï¼ˆAMPï¼‰ï¼Œæ¢¯åº¦è£å‰ªï¼Œwarmup+cosine lrè°ƒåº¦
6. å¯ä¼¸ç¼©æ€§ï¼šæ”¯æŒå†»ç»“/è§£å†» backbone çš„åˆ†æ®µè®­ç»ƒå’Œ layer-wise lr
7. è¯Šæ–­å·¥å…·ï¼šå¯è§†åŒ–é¢„æµ‹ã€è‡ªåŠ¨ git æäº¤ä¿ç•™

ä½¿ç”¨è¯´æ˜ï¼ˆç®€è¦ï¼‰:
- æ”¯æŒå‚æ•° --use-all-regions ä¸ --accum-stepsï¼Œé»˜è®¤ä¸åˆå¹¶æ‰€æœ‰åœ°åŒºï¼Œaccum-steps=1
- æ¨èæµç¨‹ï¼šå…ˆç”¨å°æ‰¹é‡ï¼ˆbs=4, epochs=20ï¼‰åšè¿‡æ‹Ÿåˆæµ‹è¯•ï¼Œå†ç”¨ --use-all-regions å¢é‡è®­ç»ƒ
"""

import os
import sys
import argparse
import logging
import numpy as np
from datetime import datetime

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import LambdaLR
from torch.cuda.amp import autocast, GradScaler
from torch.utils.tensorboard import SummaryWriter

sys.path.insert(0, '/root/codes/fire0226/MambaVision')
from mambavision import create_model

import rasterio

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

DEFAULT_DATA_DIR = '/root/autodl-tmp/training'
DEFAULT_PRETRAIN_DIR = '/root/autodl-tmp/pretrained'
DEFAULT_OUTPUT_DIR = '/root/autodl-tmp/training/output'
DEFAULT_TENSORBOARD_DIR = '/root/tf-logs'


# ============================================================================
# ç®€åŒ–ç‰ˆæŸå¤±å‡½æ•° - çº¯Dice Lossï¼ˆå¯¹ä¸å¹³è¡¡æ•°æ®æœ€é²æ£’ï¼‰
# ============================================================================

class DiceLoss(nn.Module):
    """Dice Loss - ä½¿ç”¨sigmoidï¼Œé€‚ç”¨äºå•é€šé“è¾“å‡º"""
    def __init__(self, smooth=1.0):
        super().__init__()
        self.smooth = smooth
    
    def forward(self, pred, target):
        # pred: [B, 1, H, W], target: [B, H, W]
        probs = torch.sigmoid(pred).squeeze(1)  # [B, H, W]
        target_fg = (target == 1).float()
        
        intersection = (probs * target_fg).sum()
        union = probs.sum() + target_fg.sum()
        
        dice = (2. * intersection + self.smooth) / (union + self.smooth)
        return 1 - dice


class FocalDiceLoss(nn.Module):
    """Focal + Dice ç»„åˆ - é€‚ç”¨äºå•é€šé“è¾“å‡º"""
    def __init__(self, dice_weight=1.0, focal_weight=0.5, gamma=2.0):
        super().__init__()
        self.dice_weight = dice_weight
        self.focal_weight = focal_weight
        self.gamma = gamma
        self.dice = DiceLoss()
    
    def forward(self, pred, target):
        # Dice
        dice = self.dice(pred, target)
        
        # Focal (ä½¿ç”¨BCE)
        bce = F.binary_cross_entropy_with_logits(pred.squeeze(1), target.float(), reduction='none')
        probs = torch.sigmoid(pred).squeeze(1)
        pt = probs * target.float() + (1 - probs) * (1 - target.float())
        focal = ((1 - pt) ** self.gamma * bce).mean()
        
        return self.dice_weight * dice + self.focal_weight * focal


# ============================================================================
# æ¨¡å‹
# ============================================================================

class SimpleDecoder(nn.Module):
    """ç®€åŒ–è§£ç å™¨ - æ›´æ˜“è®­ç»ƒ"""
    def __init__(self, encoder_dim, num_classes):
        super().__init__()
        
        # æ¸è¿›ä¸Šé‡‡æ ·
        self.dec1 = nn.Sequential(
            nn.Conv2d(encoder_dim, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
        )
        
        self.dec2 = nn.Sequential(
            nn.Conv2d(256, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
        )
        
        self.dec3 = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
        )
        
        self.final = nn.Conv2d(64, num_classes, 1)
        
        self._init_weights()
    
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
    
    def forward(self, x, input_shape):
        x = self.dec1(x)
        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
        
        x = self.dec2(x)
        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
        
        x = self.dec3(x)
        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
        
        x = self.final(x)
        x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)
        
        return x


class FireDetectionModel(nn.Module):
    def __init__(self, model_name='mamba_vision_S', num_classes=2, 
                 input_channels=3, pretrained=True, pretrained_path=None):
        super().__init__()
        
        # éª¨å¹²
        self.backbone = create_model(model_name, pretrained=False, num_classes=num_classes)
        
        # ä¿®æ”¹è¾“å…¥
        if input_channels != 3:
            self._modify_input(input_channels)
        
        # åŠ è½½é¢„è®­ç»ƒ
        if pretrained and pretrained_path:
            self._load_pretrained(pretrained_path)
        
        # ç®€åŒ–è§£ç å™¨
        dims = {'mamba_vision_T': 640, 'mamba_vision_S': 768, 
                'mamba_vision_B': 1024, 'mamba_vision_L': 1568}
        encoder_dim = dims.get(model_name, 768)
        
        self.decoder = SimpleDecoder(encoder_dim, num_classes)
        self.num_classes = num_classes
    
    def _modify_input(self, input_channels):
        if hasattr(self.backbone, 'patch_embed') and hasattr(self.backbone.patch_embed, 'conv_down'):
            conv = self.backbone.patch_embed.conv_down[0]
            new_conv = nn.Conv2d(input_channels, conv.out_channels, 
                               kernel_size=conv.kernel_size, stride=conv.stride,
                               padding=conv.padding, bias=conv.bias is not None)
            with torch.no_grad():
                n = conv.weight.size(1)
                repeat = (input_channels + n - 1) // n
                w = conv.weight.repeat(1, repeat, 1, 1)
                new_conv.weight.copy_(w[:, :input_channels, :, :])
                if conv.bias is not None:
                    new_conv.bias.copy_(conv.bias)
            self.backbone.patch_embed.conv_down[0] = new_conv
    
    def _load_pretrained(self, path):
        ckpt = torch.load(path, map_location='cpu')
        state = ckpt.get('state_dict', ckpt.get('model', ckpt))
        state = {k: v for k, v in state.items() if not k.startswith('head.')}
        self.backbone.load_state_dict(state, strict=False)
        logger.info(f"Loaded pretrained: {path}")
    
    def forward(self, x):
        B, C, H, W = x.shape
        x = self.backbone.patch_embed(x)
        for level in self.backbone.levels:
            x = level(x)
        x = self.backbone.norm(x)
        x = self.decoder(x, (H, W))
        return x
    
    def freeze_backbone(self):
        """å†»ç»“backboneï¼Œåªè®­ç»ƒdecoder"""
        for param in self.backbone.parameters():
            param.requires_grad = False
        logger.info("Backbone frozen, only training decoder")
    
    def unfreeze_backbone(self):
        """è§£å†»backbone"""
        for param in self.backbone.parameters():
            param.requires_grad = True
        logger.info("Backbone unfrozen")


# ============================================================================
# æ•°æ®é›† - æé«˜min_fg_pixelsè¿‡æ»¤å™ªå£°
# ============================================================================

class FireDataset(Dataset):
    def __init__(self, data_dir, region, bands=[7,6,2], mode='train', 
                 split=0.8, seed=42, min_fg_pixels=50):  # æé«˜åˆ°50è¿‡æ»¤å™ªå£°
        self.raw_dir = os.path.join(data_dir, region, 'raw')
        self.label_dir = os.path.join(data_dir, region, 'mask_label')
        self.bands = bands
        self.mode = mode
        
        # æ‰«æå¹¶è¿‡æ»¤
        samples = self._scan_samples()
        self.samples = self._filter_fire(samples, min_fg_pixels)
        
        # åˆ’åˆ†
        np.random.seed(seed)
        indices = np.random.permutation(len(self.samples))
        split_idx = int(len(indices) * split)
        
        if mode == 'train':
            self.indices = indices[:split_idx]
        else:
            self.indices = indices[split_idx:]
        
        logger.info(f"[{mode}] {len(self.indices)} patches (min_fg={min_fg_pixels})")
    
    def _scan_samples(self):
        samples = []
        for f in os.listdir(self.label_dir):
            if '_voting_' in f and f.endswith('.tif'):
                raw_f = f.replace('_voting_', '_').replace('.tif', '.tif')
                raw_path = os.path.join(self.raw_dir, raw_f)
                label_path = os.path.join(self.label_dir, f)
                if os.path.exists(raw_path):
                    samples.append({'raw': raw_path, 'label': label_path})
        return samples
    
    def _filter_fire(self, samples, min_fg):
        filtered = []
        for s in samples:
            try:
                with rasterio.open(s['label']) as src:
                    label = src.read(1)
                fg = (label == 1).sum()
                if fg >= min_fg:
                    s['fg_count'] = int(fg)
                    s['fg_ratio'] = fg / label.size
                    filtered.append(s)
            except:
                pass
        logger.info(f"Filtered: {len(filtered)}/{len(samples)} have >= {min_fg} fire pixels")
        return filtered
    
    def __len__(self):
        return len(self.indices)
    
    def __getitem__(self, idx):
        s = self.samples[self.indices[idx]]
        
        with rasterio.open(s['raw']) as src:
            bands = self.bands if max(self.bands) <= src.count else list(range(1, src.count+1))
            image = src.read(bands)
        
        with rasterio.open(s['label']) as src:
            label = src.read(1)
        
        # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
        if np.all(image == 0) or np.all(label == 0):
            logger.warning(f"Zero data detected in sample {idx}")
        
        # å½’ä¸€åŒ–
        image = image.astype(np.float32)
        for i in range(image.shape[0]):
            b = image[i]
            if b.max() > b.min():
                image[i] = (b - b.min()) / (b.max() - b.min())
            else:
                image[i] = b / (b.max() + 1e-8) if b.max() > 0 else b
        
        if self.mode == 'train':
            image, label = self._augment(image, label)
        
        return torch.from_numpy(image).float(), torch.from_numpy(label.astype(np.int64))
    
    def _augment(self, img, lbl):
        # éšæœºæ°´å¹³ç¿»è½¬
        if np.random.rand() > 0.5:
            img = np.flip(img, axis=2).copy()
            lbl = np.flip(lbl, axis=1).copy()
        # éšæœºå‚ç›´ç¿»è½¬
        if np.random.rand() > 0.5:
            img = np.flip(img, axis=1).copy()
            lbl = np.flip(lbl, axis=0).copy()
        # éšæœºæ—‹è½¬90åº¦ï¼ˆæ–°å¢ï¼‰
        if np.random.rand() > 0.5:
            k = np.random.randint(1, 4)  # æ—‹è½¬90, 180, æˆ– 270åº¦
            img = np.rot90(img, k, axes=(1, 2)).copy()
            lbl = np.rot90(lbl, k).copy()
        # éšæœºäº®åº¦æŠ–åŠ¨
        if np.random.rand() < 0.5:
            factor = 0.8 + 0.4 * np.random.rand()  # [0.8, 1.2]
            img = img * factor
        # éšæœºé«˜æ–¯å™ªå£°
        if np.random.rand() < 0.3:
            sigma = 0.005 + 0.02 * np.random.rand()
            noise = np.random.normal(0, sigma, img.shape).astype(np.float32)
            img = img + noise
        # è£å‰ªåˆ°åˆæ³•èŒƒå›´
        img = np.clip(img, 0.0, 1.0)
        return img, lbl


# ============================================================================
# è®­ç»ƒ
# ============================================================================

def train_epoch(model, loader, criterion, optimizer, device, scaler, use_amp, max_grad_norm=1.0, accum_steps=1):
    """è®­ç»ƒä¸€ä¸ªepochï¼Œæ”¯æŒæ¢¯åº¦ç´¯ç§¯ä¸AMP"""
    model.train()
    total_loss = 0.0
    tp = fp = fn = 0
    optimizer.zero_grad()
    
    for i, (images, labels) in enumerate(loader):
        images, labels = images.to(device), labels.to(device)
        with autocast(enabled=use_amp):
            outputs = model(images)
            loss = criterion(outputs, labels) / float(accum_steps)
        if use_amp:
            scaler.scale(loss).backward()
        else:
            loss.backward()
        
        # æ¢¯åº¦ç´¯ç§¯ï¼šæ¯ accum_steps æ­¥æ›´æ–°ä¸€æ¬¡
        if (i + 1) % accum_steps == 0:
            if use_amp:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
                scaler.step(optimizer)
                scaler.update()
            else:
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
                optimizer.step()
            optimizer.zero_grad()
        
        # æ¢å¤çœŸå®lossç”¨äºæ—¥å¿—
        total_loss += loss.item() * float(accum_steps)
        # å•é€šé“è¾“å‡ºä½¿ç”¨sigmoidé˜ˆå€¼
        probs = torch.sigmoid(outputs).squeeze(1)
        preds = (probs > 0.5).long()
        tp += ((preds == 1) & (labels == 1)).sum().item()
        fp += ((preds == 1) & (labels == 0)).sum().item()
        fn += ((preds == 0) & (labels == 1)).sum().item()
        
        if i % 10 == 0:
            p = tp / (tp + fp + 1e-8) * 100
            r = tp / (tp + fn + 1e-8) * 100
            f1 = 2 * p * r / (p + r + 1e-8)
            logger.info(f'  [{i}/{len(loader)}] Loss: {loss.item()*accum_steps:.4f} P:{p:.1f}% R:{r:.1f}% F1:{f1:.1f}%')
    
    avg_loss = total_loss / len(loader)
    precision = tp / (tp + fp + 1e-8) * 100
    recall = tp / (tp + fn + 1e-8) * 100
    f1 = 2 * precision * recall / (precision + recall + 1e-8)
    
    logger.info(f'Train - Loss: {avg_loss:.4f} P:{precision:.2f}% R:{recall:.2f}% F1:{f1:.2f}%')
    return avg_loss, f1


@torch.no_grad()
def validate(model, loader, criterion, device):
    model.eval()
    total_loss = 0
    tp = fp = fn = 0
    
    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = criterion(outputs, labels)
        total_loss += loss.item()
        # å•é€šé“è¾“å‡ºä½¿ç”¨sigmoidé˜ˆå€¼
        probs = torch.sigmoid(outputs).squeeze(1)
        preds = (probs > 0.5).long()
        tp += ((preds == 1) & (labels == 1)).sum().item()
        fp += ((preds == 1) & (labels == 0)).sum().item()
        fn += ((preds == 0) & (labels == 1)).sum().item()
    
    avg_loss = total_loss / len(loader)
    precision = tp / (tp + fp + 1e-8) * 100
    recall = tp / (tp + fn + 1e-8) * 100
    f1 = 2 * precision * recall / (precision + recall + 1e-8)
    iou = tp / (tp + fp + fn + 1e-8) * 100
    
    logger.info(f'Val - Loss: {avg_loss:.4f} F1:{f1:.2f}% IoU:{iou:.2f}% P:{precision:.2f}% R:{recall:.2f}%')
    return avg_loss, f1, iou, precision, recall


# ============================================================================
# Warmupè°ƒåº¦å™¨
# ============================================================================

class WarmupCosineScheduler:
    def __init__(self, optimizer, warmup_epochs, total_epochs, base_lr, min_lr=1e-7):
        self.optimizer = optimizer
        self.warmup_epochs = warmup_epochs
        self.total_epochs = total_epochs
        self.base_lr = base_lr
        self.min_lr = min_lr
    
    def step(self, epoch):
        if epoch < self.warmup_epochs:
            # Warmupé˜¶æ®µçº¿æ€§å¢åŠ 
            lr = self.base_lr * (epoch + 1) / self.warmup_epochs
        else:
            # Cosineé€€ç«
            progress = (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)
            lr = self.min_lr + (self.base_lr - self.min_lr) * 0.5 * (1 + np.cos(np.pi * progress))
        
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr
        
        return lr


# ============================================================================
# å¯è§†åŒ–
# ============================================================================

def visualize_predictions(model, loader, device, num_samples=4, save_dir='./visualizations'):
    """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
    os.makedirs(save_dir, exist_ok=True)
    model.eval()
    
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    
    count = 0
    with torch.no_grad():
        for images, labels in loader:
            if count >= num_samples:
                break
            
            images = images.to(device)
            outputs = model(images)
            probs = F.softmax(outputs, dim=1)[:, 1, :, :]
            preds = outputs.argmax(dim=1)
            
            # ä¿å­˜å‰å‡ ä¸ªæ ·æœ¬
            for i in range(min(2, images.size(0))):
                if count >= num_samples:
                    break
                
                fig, axes = plt.subplots(1, 4, figsize=(16, 4))
                
                # è¾“å…¥å›¾åƒ (RGBåˆæˆ)
                img = images[i].cpu().numpy()
                if img.shape[0] >= 3:
                    rgb = np.stack([img[0], img[1], img[2]], axis=-1)
                    axes[0].imshow(rgb)
                else:
                    axes[0].imshow(img[0], cmap='gray')
                axes[0].set_title('Input')
                axes[0].axis('off')
                
                # æ ‡ç­¾
                axes[1].imshow(labels[i].cpu().numpy(), cmap='hot')
                axes[1].set_title('Ground Truth')
                axes[1].axis('off')
                
                # é¢„æµ‹æ¦‚ç‡
                axes[2].imshow(probs[i].cpu().numpy(), cmap='hot', vmin=0, vmax=1)
                axes[2].set_title('Pred Probability')
                axes[2].axis('off')
                
                # é¢„æµ‹ç»“æœ
                axes[3].imshow(preds[i].cpu().numpy(), cmap='hot')
                axes[3].set_title('Prediction')
                axes[3].axis('off')
                
                plt.tight_layout()
                plt.savefig(f'{save_dir}/sample_{count}.png', dpi=150)
                plt.close()
                
                count += 1
    
    logger.info(f"Saved {count} visualizations to {save_dir}")


# ============================================================================
# Gitè‡ªåŠ¨æäº¤åŠŸèƒ½
# ============================================================================

def git_commit_auto(message):
    """è‡ªåŠ¨æäº¤ä»£ç å˜æ›´åˆ°Git"""
    try:
        import subprocess
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´
        result = subprocess.run(['git', 'status', '--porcelain'], 
                              capture_output=True, text=True, cwd='/root/codes/fire0226/selfCodes')
        
        if result.stdout.strip():
            # æœ‰å˜æ›´ï¼Œæ‰§è¡Œæäº¤
            subprocess.run(['git', 'add', '-A'], cwd='/root/codes/fire0226/selfCodes', check=True)
            subprocess.run(['git', 'commit', '-m', message], cwd='/root/codes/fire0226/selfCodes', check=True)
            
            # å°è¯•æ¨é€
            push_result = subprocess.run(['git', 'push', 'origin', 'main'], 
                                        capture_output=True, text=True, 
                                        cwd='/root/codes/fire0226/selfCodes')
            if push_result.returncode == 0:
                logger.info(f'âœ… Git synced: {message[:50]}...')
            else:
                logger.warning('âš ï¸ Git commit OK but push failed')
        else:
            logger.info('â„¹ï¸ No code changes to commit')
            
    except Exception as e:
        logger.warning(f'âš ï¸ Git auto-commit failed: {e}')


# ============================================================================
# Main
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description='Fire Detection Training')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('region', type=str, help='Region name (e.g., Asia1)')
    parser.add_argument('--data-dir', type=str, default=DEFAULT_DATA_DIR)
    parser.add_argument('--output-dir', type=str, default=None)
    parser.add_argument('--tensorboard-dir', type=str, default=DEFAULT_TENSORBOARD_DIR)
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--bands', type=int, nargs='+', default=[7, 6, 2])
    parser.add_argument('--min-fg-pixels', type=int, default=50, 
                       help='Min fire pixels to filter noise (default: 50)')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model', type=str, default='mamba_vision_S')
    parser.add_argument('--pretrained', action='store_true', default=True)
    parser.add_argument('--freeze-backbone-epochs', type=int, default=10,
                       help='Freeze backbone for N epochs (default: 10)')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--batch-size', type=int, default=8,
                       help='Batch size (default: 8)')
    parser.add_argument('--lr', type=float, default=1e-4,
                       help='Learning rate (default: 1e-4)')
    parser.add_argument('--weight-decay', type=float, default=0.01)
    parser.add_argument('--max-grad-norm', type=float, default=1.0,
                       help='Max gradient norm for clipping (default: 1.0)')
    parser.add_argument('--num-workers', type=int, default=4)
    parser.add_argument('--warmup-epochs', type=int, default=5,
                       help='Warmup epochs, 5% of total (default: 5)')
    
    # æ—©åœå‚æ•° - åŸºäºF1
    parser.add_argument('--early-stop-patience', type=int, default=3,
                       help='Early stop patience based on F1 (default: 3)')
    parser.add_argument('--early-stop-min-f1', type=float, default=40.0,
                       help='Minimum F1 to consider successful (default: 40%)')
    
    # å…¶ä»–
    parser.add_argument('--use-amp', action='store_true', default=True)
    parser.add_argument('--tensorboard', action='store_true', default=True)
    parser.add_argument('--visualize', action='store_true', default=False)
    parser.add_argument('--use-all-regions', action='store_true', default=False,
                        help='If set, use all subdirectories under data-dir as regions for training')
    parser.add_argument('--accum-steps', type=int, default=1,
                        help='Gradient accumulation steps to simulate larger batch sizes (default:1)')
    
    args = parser.parse_args()
    
    # è®­ç»ƒå‰è‡ªåŠ¨æäº¤
    git_commit_auto(f"Pre-train: Start training {args.region} with lr={args.lr}, bs={args.batch_size}")
    
    torch.manual_seed(42)
    np.random.seed(42)
    
    if args.output_dir is None:
        args.output_dir = os.path.join(DEFAULT_OUTPUT_DIR, args.region)
    os.makedirs(args.output_dir, exist_ok=True)
    
    # TensorBoard
    writer = None
    if args.tensorboard:
        exp_name = f"fire_{args.region}_{datetime.now().strftime('%m%d_%H%M')}"
        tb_dir = os.path.join(args.tensorboard_dir, exp_name)
        writer = SummaryWriter(tb_dir)
        logger.info(f'TensorBoard: {tb_dir}')
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f'Device: {device}')
    
    # æ•°æ®é›† (æ”¯æŒå¤šåŒºåŸŸåˆå¹¶è®­ç»ƒä¸æ ·æœ¬åŠ æƒé‡‡æ ·)
    if args.use_all_regions:
        regions = [d for d in os.listdir(args.data_dir) if os.path.isdir(os.path.join(args.data_dir, d))]
        train_datasets = [FireDataset(args.data_dir, r, args.bands, 'train', min_fg_pixels=args.min_fg_pixels) for r in regions]
        val_datasets = [FireDataset(args.data_dir, r, args.bands, 'val', min_fg_pixels=args.min_fg_pixels) for r in regions]
        train_ds = torch.utils.data.ConcatDataset(train_datasets)
        val_ds = torch.utils.data.ConcatDataset(val_datasets)
        logger.info(f'Using all regions for training: {regions}')
    else:
        train_ds = FireDataset(args.data_dir, args.region, args.bands, 'train', min_fg_pixels=args.min_fg_pixels)
        val_ds = FireDataset(args.data_dir, args.region, args.bands, 'val', min_fg_pixels=args.min_fg_pixels)
    
    # ä¸ºäº†ç¼“è§£æ ·æœ¬çº§åˆ«ä¸å¹³è¡¡ï¼ŒåŸºäºæ¯ä¸ªæ ·æœ¬çš„fg_countåšåŠ æƒé‡‡æ ·ï¼ˆè¶Šå°çš„fg_countæƒé‡è¶Šå¤§ï¼‰
    sampler = None
    try:
        all_counts = []
        if isinstance(train_ds, torch.utils.data.ConcatDataset):
            for ds in train_ds.datasets:
                all_counts.extend([s.get('fg_count', 0) for s in ds.samples])
        else:
            all_counts = [s.get('fg_count', 0) for s in train_ds.samples]
        if len(all_counts) > 0:
            weights = [1.0 / (c + 1) for c in all_counts]
            sampler = torch.utils.data.WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)
    except Exception as e:
        logger.warning(f'Could not create sampler: {e}')
    
    if sampler is not None:
        train_loader = DataLoader(train_ds, batch_size=args.batch_size, sampler=sampler,
                                  num_workers=args.num_workers, pin_memory=True)
    else:
        train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True,
                                  num_workers=args.num_workers, pin_memory=True)
    val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False,
                           num_workers=args.num_workers, pin_memory=True)
    
    # æ¨¡å‹
    pretrained_path = os.path.join(DEFAULT_PRETRAIN_DIR, 'mambavision_small_1k.pth') if args.pretrained else None
    model = FireDetectionModel(args.model, 1, len(args.bands), args.pretrained, pretrained_path).to(device)
    logger.info(f'Params: {sum(p.numel() for p in model.parameters())/1e6:.2f}M')
    
    # æŸå¤± - Focal + Dice ç»„åˆä»¥ç¼“è§£æ­£è´Ÿæ ·æœ¬æåº¦ä¸å¹³è¡¡
    criterion = FocalDiceLoss(dice_weight=1.0, focal_weight=1.0, gamma=2.0)
    logger.info('Using Focal + Dice Loss')
    
    # ä¼˜åŒ–å™¨
    optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    
    # Warmup + Cosineè°ƒåº¦
    scheduler = WarmupCosineScheduler(optimizer, args.warmup_epochs, args.epochs, args.lr)
    scaler = GradScaler() if args.use_amp else None
    
    # è®­ç»ƒçŠ¶æ€
    best_f1 = 0.0
    best_epoch = 0
    epochs_no_improve = 0
    
    for epoch in range(1, args.epochs + 1):
        current_lr = scheduler.step(epoch - 1)
        logger.info(f'\nEpoch {epoch}/{args.epochs} (lr={current_lr:.2e})')
        logger.info('-' * 60)
        
        # é˜¶æ®µæ€§è§£å†»backbone - æ›´çµæ´»çš„ç­–ç•¥
        if epoch == 1 and args.freeze_backbone_epochs > 0:
            model.freeze_backbone()
        elif epoch == args.freeze_backbone_epochs + 1:
            model.unfreeze_backbone()
            # è§£å†»åä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡
            optimizer = AdamW([
                {'params': model.backbone.parameters(), 'lr': args.lr * 0.1},
                {'params': model.decoder.parameters(), 'lr': args.lr}
            ], weight_decay=args.weight_decay)
            logger.info('Optimizer reinitialized with layer-wise lr')
        
        # è®­ç»ƒ
        train_loss, train_f1 = train_epoch(model, train_loader, criterion, optimizer, device, scaler, args.use_amp, args.max_grad_norm, accum_steps=args.accum_steps)
        
        # éªŒè¯
        val_loss, val_f1, val_iou, val_p, val_r = validate(model, val_loader, criterion, device)
        
        # TensorBoard
        if writer:
            writer.add_scalar('Loss/train', train_loss, epoch)
            writer.add_scalar('Loss/val', val_loss, epoch)
            writer.add_scalar('Metrics/F1', val_f1, epoch)
            writer.add_scalar('Metrics/IoU', val_iou, epoch)
            writer.add_scalar('Metrics/Precision', val_p, epoch)
            writer.add_scalar('Metrics/Recall', val_r, epoch)
            writer.add_scalar('Train/lr', current_lr, epoch)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºF1ï¼‰
        if val_f1 > best_f1:
            best_f1 = val_f1
            best_epoch = epoch
            epochs_no_improve = 0
            torch.save({
                'epoch': epoch, 'model': model.state_dict(),
                'f1': val_f1, 'iou': val_iou, 'p': val_p, 'r': val_r,
                'args': vars(args)
            }, os.path.join(args.output_dir, 'best_model.pth'))
            logger.info(f'âœ“ Saved best model (F1: {best_f1:.2f}%)')
        else:
            epochs_no_improve += 1
            logger.info(f'  No F1 improvement for {epochs_no_improve} epochs')
        
        # æ—©åœ - 3epochæ— F1æå‡å³åœ
        if epochs_no_improve >= args.early_stop_patience:
            logger.warning(f'\nğŸ›‘ Early stopping! No F1 improvement for {args.early_stop_patience} epochs')
            logger.warning(f'   Best F1: {best_f1:.2f}% at epoch {best_epoch}')
            
            if best_f1 < args.early_stop_min_f1:
                logger.warning(f'   Warning: Best F1 {best_f1:.2f}% < {args.early_stop_min_f1}% target')
            break
    
    # å¯è§†åŒ–
    if args.visualize:
        visualize_predictions(model, val_loader, device)
    
    logger.info(f'\nğŸ† Best: F1 {best_f1:.2f}% (P:{val_p:.1f}%, R:{val_r:.1f}%) @ epoch {best_epoch}')
    
    # è®­ç»ƒåè‡ªåŠ¨æäº¤
    git_commit_auto(f"Post-train: {args.region} best F1={best_f1:.2f}% @ epoch {best_epoch}")
    
    if writer:
        writer.close()


if __name__ == '__main__':
    main()
