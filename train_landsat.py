#!/usr/bin/env python3
"""
train_landsat.py - ç«ç‚¹æ£€æµ‹æ·±åº¦ä¼˜åŒ–ç‰ˆï¼ˆä¸‰å±‚æ¶æ„æ”¹è¿›ï¼‰
GitHub: https://github.com/billy31/2602_fy4b_activefire

ã€2025-02-27 ä¸‰å±‚æ¶æ„å…¨é¢ä¼˜åŒ–ã€‘:
ã€2026-02-27 æ›´æ–°ã€‘
- æ ‡ç­¾ç»Ÿä¸€äºŒå€¼åŒ–ï¼ˆlabel > 0ï¼‰ï¼Œé¿å…255/å¤šç±»å¯¼è‡´F1ä¸º0
- åŠ¨æ€é˜ˆå€¼æœç´¢æ‰©å±•åˆ°0.05-0.95
- åŠ å…¥è´Ÿæ ·æœ¬ä¸‹é‡‡æ ·ï¼Œé¿å…è®­ç»ƒé›†å…¨æ­£å¯¼è‡´éªŒè¯é˜ˆå€¼è¿‡é«˜

=== LV-1: é‡‡æ ·ä¸é˜ˆå€¼ä¼˜åŒ– ===
1. ä¿®æ­£é‡‡æ ·æƒé‡ï¼šä»"fg_countå€’æ•°"æ”¹ä¸º"å›°éš¾æ ·æœ¬æŒ–æ˜+ç±»åˆ«å¹³è¡¡"
   - åŸï¼šweight = 1/(fg_count+1) å¯¼è‡´è¿‡åº¦å…³æ³¨æå°ç›®æ ‡
   - æ–°ï¼šåŸºäºIoUéš¾åº¦ + ç«ç‚¹/èƒŒæ™¯åƒç´ æ¯”ä¾‹åŠ¨æ€åŠ æƒ
   
2. åŠ¨æ€é˜ˆå€¼æœç´¢ï¼šéªŒè¯æ—¶è‡ªåŠ¨æœç´¢æœ€ä¼˜F1é˜ˆå€¼ï¼ˆ0.1-0.9èŒƒå›´ï¼‰
   - æ›¿ä»£å›ºå®š0.5é˜ˆå€¼ï¼Œé€‚åº”ä¸åŒè®­ç»ƒé˜¶æ®µå’Œæ•°æ®åˆ†å¸ƒ
   
3. Diceè®¡ç®—æ”¹è¿›ï¼šper-sample Dice + å¹³æ»‘å› å­è‡ªé€‚åº”
   - é¿å…å…¨å±€Diceå¯¹å°ç›®æ ‡çš„æ¢¯åº¦ç¨€é‡Š

=== LV-2: è®­ç»ƒç­–ç•¥ä¸æ•°æ®æµä¼˜åŒ– ===
4. æ¸è¿›å¼åˆ†å±‚è®­ç»ƒç­–ç•¥ï¼ˆæ›¿ä»£ç®€å•å†»ç»“ï¼‰
   - Stage 1 (1-5 epoch): å…¨éƒ¨å¯è®­ç»ƒï¼Œbackbone LR=1e-5, decoder LR=1e-4
   - Stage 2 (6-20 epoch): æ­£å¸¸è®­ç»ƒï¼Œç»Ÿä¸€LR=1e-4
   - ä¿®å¤åŸschedulerä¸optimizeré‡å»ºå†²çªé—®é¢˜
   
5. é¥æ„Ÿä¸“ç”¨å½’ä¸€åŒ–ï¼šå…¨å±€ç™¾åˆ†ä½æ•°å½’ä¸€åŒ–
   - æ›¿ä»£é€æ ·æœ¬min-maxï¼ˆè¿‡äºå±€éƒ¨ï¼Œç ´åå…‰è°±å…³ç³»ï¼‰
   - ä½¿ç”¨ Landsat å…¨å±€ç»Ÿè®¡ (1%-99% percentile)
   
6. æ¢¯åº¦ç´¯ç§¯ä¸æ··åˆç²¾åº¦ä¼˜åŒ–ï¼šæ”¯æŒæ›´å¤§batchæ¨¡æ‹Ÿ

=== LV-3: ç½‘ç»œç»“æ„ä¸æŸå¤±å‡½æ•°ä¼˜åŒ– ===
7. å¤šå°ºåº¦ç‰¹å¾èåˆè§£ç å™¨ï¼ˆæ›¿ä»£å•å°ºåº¦ï¼‰
   - FPN-likeç»“æ„ï¼šèåˆæµ…å±‚ç»†èŠ‚ï¼ˆç«ç‚¹è¾¹ç¼˜ï¼‰+æ·±å±‚è¯­ä¹‰
   - åŒå¤´è¾“å‡ºï¼šåˆ†å‰²å¤´ + è¾¹ç¼˜ç»†åŒ–å¤´
   
8. å°ç›®æ ‡æ„ŸçŸ¥å¤åˆæŸå¤±å‡½æ•°
   - Tversky Loss (alpha=0.3, beta=0.7)ï¼šæ›´å…³æ³¨å¬å›ç‡
   - Boundary Lossï¼šå¼ºåŒ–ç«ç‚¹è¾¹ç•Œå­¦ä¹ 
   - Size-Weighted Focalï¼šå°ç›®æ ‡è·å¾—æ›´é«˜æƒé‡
   
9. é¥æ„Ÿä¸“ç”¨æ•°æ®å¢å¼º
   - å…‰è°±æ··åˆï¼ˆSpectral Mixupï¼‰ï¼šæ¨¡æ‹Ÿä¸åŒç‡ƒçƒ§å¼ºåº¦
   - é€šé“éšæœºDropoutï¼šæ¨¡æ‹Ÿäº‘å±‚é®æŒ¡/ä¼ æ„Ÿå™¨å·®å¼‚
   - ç©ºé—´å™ªå£°ï¼ˆé«˜æ–¯+æ¤’ç›ï¼‰ï¼šæå‡å¯¹FY-4Bå™ªå£°çš„é²æ£’æ€§

ç›®æ ‡ï¼šè¾¾åˆ° B5+B6+B7 æ³¢æ®µç»„åˆä¸‹ 94%+ F1-Score
"""

import os
import sys
import argparse
import logging
import numpy as np
from datetime import datetime
from typing import List, Dict, Tuple, Optional

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from torch.optim import AdamW
from torch.cuda.amp import autocast, GradScaler
from torch.utils.tensorboard import SummaryWriter

sys.path.insert(0, '/root/codes/fire0226/MambaVision')
from mambavision import create_model

import rasterio
from scipy.ndimage import distance_transform_edt

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

DEFAULT_DATA_DIR = '/root/autodl-tmp/training'
DEFAULT_PRETRAIN_DIR = '/root/autodl-tmp/pretrained'
DEFAULT_OUTPUT_DIR = '/root/autodl-tmp/training/output'
DEFAULT_TENSORBOARD_DIR = '/root/tf-logs'

# ============================================================================
# å…¨å±€å½’ä¸€åŒ–ç»Ÿè®¡ï¼ˆLandsat-8 å…¸å‹å€¼ï¼ŒåŸºäºçœŸå®æ•°æ®ç»Ÿè®¡ï¼‰
# ============================================================================

# Landsat-8 å„æ³¢æ®µå…¨å±€ç™¾åˆ†ä½æ•°ç»Ÿè®¡ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
LANDSAT_GLOBAL_STATS = {
    1: {'p1': 7000, 'p99': 18000},   # Coastal aerosol
    2: {'p1': 7000, 'p99': 19000},   # Blue
    3: {'p1': 8000, 'p99': 22000},   # Green
    4: {'p1': 7000, 'p99': 24000},   # Red
    5: {'p1': 8000, 'p99': 30000},   # NIR - ç«ç‚¹æ£€æµ‹å…³é”®æ³¢æ®µ
    6: {'p1': 5000, 'p99': 18000},   # SWIR1 - ç«ç‚¹æ£€æµ‹å…³é”®æ³¢æ®µ
    7: {'p1': 3000, 'p99': 14000},   # SWIR2 - ç«ç‚¹æ£€æµ‹å…³é”®æ³¢æ®µ
}


def get_band_stats(band_idx: int) -> Dict[str, float]:
    """è·å–æ³¢æ®µç»Ÿè®¡å€¼"""
    # æ³¢æ®µæ˜ å°„ï¼šè¾“å…¥å¯èƒ½æ˜¯7,6,2ï¼Œéœ€è¦æ˜ å°„åˆ°æ ‡å‡†Landsatæ³¢æ®µå·
    band_mapping = {7: 7, 6: 6, 5: 5, 2: 2}
    standard_band = band_mapping.get(band_idx, band_idx)
    return LANDSAT_GLOBAL_STATS.get(standard_band, {'p1': 5000, 'p99': 20000})


# ============================================================================
# å¤åˆæŸå¤±å‡½æ•°ï¼šå°ç›®æ ‡æ„ŸçŸ¥ + è¾¹ç•Œæ„ŸçŸ¥
# ============================================================================

class TverskyLoss(nn.Module):
    """
    Tversky Loss - å¯è°ƒæ•´ç²¾ç¡®ç‡-å¬å›ç‡æƒè¡¡
    alpha: å‡é˜´æ€§æƒ©ç½š (æ›´é«˜=æ›´å…³æ³¨å¬å›ç‡)
    beta: å‡é˜³æ€§æƒ©ç½š
    """
    def __init__(self, alpha: float = 0.3, beta: float = 0.7, smooth: float = 1.0):
        super().__init__()
        self.alpha = alpha  # é™ä½alphaæ›´å…³æ³¨FNï¼ˆç«ç‚¹æ¼æ£€ï¼‰
        self.beta = beta
        self.smooth = smooth
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        # pred: [B, 1, H, W], target: [B, H, W]
        probs = torch.sigmoid(pred).squeeze(1)
        target_fg = (target > 0).float()
        
        # é€æ ·æœ¬è®¡ç®—å†å¹³å‡
        batch_size = pred.size(0)
        tversky_sum = 0.0
        
        for i in range(batch_size):
            p = probs[i].flatten()
            t = target_fg[i].flatten()
            
            tp = (p * t).sum()
            fp = (p * (1 - t)).sum()
            fn = ((1 - p) * t).sum()
            
            tversky = (tp + self.smooth) / (tp + self.alpha * fn + self.beta * fp + self.smooth)
            tversky_sum += (1 - tversky)
        
        return tversky_sum / batch_size


class BoundaryLoss(nn.Module):
    """
    è¾¹ç•ŒæŸå¤± - åŸºäºè·ç¦»å˜æ¢ï¼Œå¼ºåŒ–ç«ç‚¹è¾¹ç•Œå­¦ä¹ 
    å¯¹å°ç›®æ ‡ç‰¹åˆ«æœ‰æ•ˆ
    """
    def __init__(self, theta: float = 0.5):
        super().__init__()
        self.theta = theta
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        # pred: [B, 1, H, W], target: [B, H, W]
        probs = torch.sigmoid(pred).squeeze(1)
        target_fg = (target > 0).float()
        
        # è®¡ç®—åˆ°è¾¹ç•Œçš„è·ç¦»å›¾ï¼ˆä»…åœ¨CPUä¸Šé¢„è®¡ç®—ï¼‰
        with torch.no_grad():
            dist_maps = []
            for i in range(target.size(0)):
                t = target_fg[i].cpu().numpy()
                if t.sum() == 0:
                    dist_maps.append(np.zeros_like(t))
                    continue
                # è®¡ç®—åˆ°æœ€è¿‘ç«ç‚¹è¾¹ç•Œçš„è·ç¦»
                pos_dist = distance_transform_edt(t > 0.5)
                neg_dist = distance_transform_edt(t <= 0.5)
                boundary = (pos_dist <= 2) | (neg_dist <= 2)  # è¾¹ç•ŒåŒºåŸŸ
                dist_to_boundary = np.where(boundary, 
                                           np.minimum(pos_dist, neg_dist),
                                           0)
                dist_maps.append(dist_to_boundary)
            dist_map = torch.from_numpy(np.stack(dist_maps)).float().to(pred.device)
        
        # è¾¹ç•ŒåŒºåŸŸçš„å¤šåŠ æƒçš„BCE
        bce = F.binary_cross_entropy_with_logits(pred.squeeze(1), target_fg, reduction='none')
        weighted_bce = (dist_map + 1.0) * bce  # è¾¹ç•ŒåŒºåŸŸæƒé‡æ›´é«˜
        
        return weighted_bce.mean()


class SizeWeightedFocalLoss(nn.Module):
    """
    å°ºå¯¸åŠ æƒFocal Loss - å°ç›®æ ‡è·å¾—æ›´é«˜æƒé‡
    """
    def __init__(self, gamma: float = 2.0, alpha: float = 0.25, 
                 size_weight_power: float = 0.5):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha
        self.size_weight_power = size_weight_power  # å°ç›®æ ‡æƒé‡å¢å¼ºå› å­
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        probs = torch.sigmoid(pred).squeeze(1)
        target_fg = (target > 0).float()
        
        batch_size = pred.size(0)
        total_loss = 0.0
        
        for i in range(batch_size):
            p = probs[i]
            t = target_fg[i]
            
            # è®¡ç®—å½“å‰æ ·æœ¬ç«ç‚¹å¤§å°
            fg_pixels = t.sum().item()
            if fg_pixels > 0:
                # å°ç›®æ ‡è·å¾—æ›´é«˜æƒé‡ (1 / sqrt(fg_pixels))
                size_weight = (1.0 / (fg_pixels ** self.size_weight_power)) * 100
                size_weight = min(size_weight, 10.0)  # ä¸Šé™ä¿æŠ¤
            else:
                size_weight = 1.0
            
            # Focal loss
            bce = F.binary_cross_entropy_with_logits(pred[i].squeeze(0), t, reduction='none')
            pt = torch.where(t == 1, p, 1 - p)
            focal = ((1 - pt) ** self.gamma * bce)
            
            # ç±»åˆ«å¹³è¡¡ + å°ºå¯¸åŠ æƒ
            alpha_t = torch.where(t == 1, self.alpha, 1 - self.alpha)
            weighted_focal = (alpha_t * focal * size_weight).mean()
            
            total_loss += weighted_focal
        
        return total_loss / batch_size


class CombinedFireLoss(nn.Module):
    """
    å¤åˆæŸå¤±å‡½æ•°ï¼šTversky + Boundary + SizeWeightedFocal
    é’ˆå¯¹ç«ç‚¹æ£€æµ‹å°ç›®æ ‡ã€è¾¹ç•Œæ¨¡ç³Šçš„ç‰¹ç‚¹ä¼˜åŒ–
    """
    def __init__(self, 
                 tversky_weight: float = 1.0,
                 boundary_weight: float = 0.5,
                 focal_weight: float = 1.0,
                 tversky_alpha: float = 0.3,
                 tversky_beta: float = 0.7):
        super().__init__()
        self.tversky_weight = tversky_weight
        self.boundary_weight = boundary_weight
        self.focal_weight = focal_weight
        
        self.tversky = TverskyLoss(alpha=tversky_alpha, beta=tversky_beta)
        self.boundary = BoundaryLoss()
        self.focal = SizeWeightedFocalLoss(gamma=2.0, alpha=0.25)
    
    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        loss_tversky = self.tversky(pred, target)
        loss_boundary = self.boundary(pred, target)
        loss_focal = self.focal(pred, target)
        
        total = (self.tversky_weight * loss_tversky + 
                 self.boundary_weight * loss_boundary + 
                 self.focal_weight * loss_focal)
        
        return total


# ============================================================================
# å¤šå°ºåº¦ç‰¹å¾èåˆè§£ç å™¨ï¼ˆFPN-likeï¼‰
# ============================================================================

class MultiscaleDecoder(nn.Module):
    """
    å¤šå°ºåº¦è§£ç å™¨ï¼šèåˆå¤šå±‚çº§ç‰¹å¾
    - ä½¿ç”¨è·³è·ƒè¿æ¥èåˆæµ…å±‚ç»†èŠ‚ï¼ˆç«ç‚¹è¾¹ç¼˜ä¿¡æ¯ï¼‰
    - æ¸è¿›ä¸Šé‡‡æ · + ç‰¹å¾èåˆ
    - åŒå¤´è¾“å‡ºï¼šä¸»åˆ†å‰² + è¾¹ç¼˜ç»†åŒ–
    """
    def __init__(self, encoder_dim: int, num_classes: int = 1):
        super().__init__()
        
        # å¤šçº§ç‰¹å¾å¤„ç†ï¼ˆå‡è®¾encoderè¾“å‡ºå¤šå°ºåº¦ç‰¹å¾ï¼‰
        # è¿™é‡Œç®€åŒ–ä¸ºä»å•ä¸€ç‰¹å¾å›¾æ„å»ºå¤šå°ºåº¦
        
        # ä¸Šé‡‡æ ·è·¯å¾„
        self.up1 = nn.Sequential(
            nn.Conv2d(encoder_dim, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
        )
        
        self.up2 = nn.Sequential(
            nn.Conv2d(512, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
        )
        
        self.up3 = nn.Sequential(
            nn.Conv2d(256, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
        )
        
        self.up4 = nn.Sequential(
            nn.Conv2d(128, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
        )
        
        # ä¸»åˆ†å‰²å¤´
        self.seg_head = nn.Conv2d(64, num_classes, 1)
        
        # è¾¹ç¼˜ç»†åŒ–å¤´ï¼ˆè¾…åŠ©ç›‘ç£ï¼‰
        self.edge_head = nn.Sequential(
            nn.Conv2d(64, 32, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 1, 1),
        )
        
        self._init_weights()
    
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
    
    def forward(self, x: torch.Tensor, input_shape: Tuple[int, int]) -> Tuple[torch.Tensor, torch.Tensor]:
        # x: [B, encoder_dim, H', W']
        
        # æ¸è¿›ä¸Šé‡‡æ ·
        x = self.up1(x)
        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
        
        x = self.up2(x)
        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
        
        x = self.up3(x)
        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
        
        x = self.up4(x)
        
        # ä¸»åˆ†å‰²è¾“å‡º
        seg = self.seg_head(x)
        seg = F.interpolate(seg, size=input_shape, mode='bilinear', align_corners=False)
        
        # è¾¹ç¼˜è¾“å‡ºï¼ˆä¸Šé‡‡æ ·åˆ°åŸå›¾å°ºå¯¸ï¼‰
        edge = self.edge_head(x)
        edge = F.interpolate(edge, size=input_shape, mode='bilinear', align_corners=False)
        
        return seg, edge


# ============================================================================
# æ”¹è¿›çš„æ¨¡å‹æ¶æ„
# ============================================================================

class FireDetectionModelV2(nn.Module):
    """
    ç«ç‚¹æ£€æµ‹æ¨¡å‹ V2
    - å¤šå°ºåº¦è§£ç å™¨
    - åˆ†å±‚å­¦ä¹ ç‡æ”¯æŒ
    """
    def __init__(self, model_name: str = 'mamba_vision_S', 
                 num_classes: int = 1,
                 input_channels: int = 3, 
                 pretrained: bool = True, 
                 pretrained_path: Optional[str] = None):
        super().__init__()
        
        # éª¨å¹²ç½‘ç»œ
        self.backbone = create_model(model_name, pretrained=False, num_classes=num_classes)
        
        # ä¿®æ”¹è¾“å…¥å±‚
        if input_channels != 3:
            self._modify_input(input_channels)
        
        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        if pretrained and pretrained_path:
            self._load_pretrained(pretrained_path)
        
        # å¤šå°ºåº¦è§£ç å™¨
        dims = {
            'mamba_vision_T': 640,
            'mamba_vision_S': 768,
            'mamba_vision_B': 1024,
            'mamba_vision_L': 1568
        }
        encoder_dim = dims.get(model_name, 768)
        
        self.decoder = MultiscaleDecoder(encoder_dim, num_classes)
        self.num_classes = num_classes
    
    def _modify_input(self, input_channels: int):
        """ä¿®æ”¹è¾“å…¥å±‚é€šé“æ•°"""
        if hasattr(self.backbone, 'patch_embed') and hasattr(self.backbone.patch_embed, 'conv_down'):
            conv = self.backbone.patch_embed.conv_down[0]
            new_conv = nn.Conv2d(input_channels, conv.out_channels,
                               kernel_size=conv.kernel_size, stride=conv.stride,
                               padding=conv.padding, bias=conv.bias is not None)
            with torch.no_grad():
                n = conv.weight.size(1)
                repeat = (input_channels + n - 1) // n
                w = conv.weight.repeat(1, repeat, 1, 1)
                new_conv.weight.copy_(w[:, :input_channels, :, :])
                if conv.bias is not None:
                    new_conv.bias.copy_(conv.bias)
            self.backbone.patch_embed.conv_down[0] = new_conv
    
    def _load_pretrained(self, path: str):
        ckpt = torch.load(path, map_location='cpu')
        state = ckpt.get('state_dict', ckpt.get('model', ckpt))
        state = {k: v for k, v in state.items() if not k.startswith('head.')}
        self.backbone.load_state_dict(state, strict=False)
        logger.info(f"Loaded pretrained: {path}")
    
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        B, C, H, W = x.shape
        
        # Encoder
        x = self.backbone.patch_embed(x)
        for level in self.backbone.levels:
            x = level(x)
        x = self.backbone.norm(x)
        
        # Decoder (è¿”å›ä¸»åˆ†å‰² + è¾¹ç¼˜)
        seg, edge = self.decoder(x, (H, W))
        return seg, edge
    
    def get_param_groups(self, lr: float) -> List[Dict]:
        """
        è·å–åˆ†å±‚å‚æ•°ç»„
        - backboneä½¿ç”¨è¾ƒä½å­¦ä¹ ç‡
        - decoderä½¿ç”¨æ­£å¸¸å­¦ä¹ ç‡
        """
        return [
            {'params': self.backbone.parameters(), 'lr': lr * 0.1, 'name': 'backbone'},
            {'params': self.decoder.parameters(), 'lr': lr, 'name': 'decoder'},
        ]


# ============================================================================
# æ•°æ®é›† - å›°éš¾æ ·æœ¬æŒ–æ˜ + å…¨å±€å½’ä¸€åŒ–
# ============================================================================

class FireDatasetV2(Dataset):
    """
    æ”¹è¿›çš„æ•°æ®é›†ï¼š
    - å…¨å±€å½’ä¸€åŒ–ï¼ˆæ›¿ä»£å±€éƒ¨min-maxï¼‰
    - é¥æ„Ÿä¸“ç”¨å¢å¼º
    - å›°éš¾æ ·æœ¬æ ‡è®°
    """
    def __init__(self, data_dir: str, region: str, bands: List[int] = [7, 6, 2],
                 mode: str = 'train', split: float = 0.8, seed: int = 42,
                 min_fg_pixels: int = 10, use_global_norm: bool = True,
                 neg_per_pos: float = 0.5):
        self.raw_dir = os.path.join(data_dir, region, 'raw')
        self.label_dir = os.path.join(data_dir, region, 'mask_label')
        self.bands = bands
        self.mode = mode
        self.use_global_norm = use_global_norm
        self.neg_per_pos = max(0.0, float(neg_per_pos))
        self.rng = np.random.default_rng(seed)
        
        # æ‰«æå¹¶è¿‡æ»¤
        samples = self._scan_samples()
        self.samples = self._filter_fire(samples, min_fg_pixels)
        
        # åˆ’åˆ†
        np.random.seed(seed)
        indices = np.random.permutation(len(self.samples))
        split_idx = int(len(indices) * split)
        
        if mode == 'train':
            self.indices = indices[:split_idx]
        else:
            self.indices = indices[split_idx:]
        
        # è·å–æ³¢æ®µç»Ÿè®¡
        self.band_stats = [get_band_stats(b) for b in bands]
        
        logger.info(f"[{mode}] {len(self.indices)} patches (min_fg={min_fg_pixels})")
    
    def _scan_samples(self) -> List[Dict]:
        samples = []
        for f in os.listdir(self.label_dir):
            if '_voting_' in f and f.endswith('.tif'):
                raw_f = f.replace('_voting_', '_').replace('.tif', '.tif')
                raw_path = os.path.join(self.raw_dir, raw_f)
                label_path = os.path.join(self.label_dir, f)
                if os.path.exists(raw_path):
                    samples.append({'raw': raw_path, 'label': label_path})
        return samples
    
    def _filter_fire(self, samples: List[Dict], min_fg: int) -> List[Dict]:
        pos_samples = []
        neg_samples = []
        for s in samples:
            try:
                with rasterio.open(s['label']) as src:
                    label = src.read(1)
                label = self._binarize_label(label)
                fg = (label > 0).sum()
                s['fg_count'] = int(fg)
                s['fg_ratio'] = fg / label.size
                if fg >= min_fg:
                    pos_samples.append(s)
                else:
                    neg_samples.append(s)
            except:
                pass
        if len(pos_samples) == 0:
            kept = neg_samples
            logger.warning("No positive samples found after filtering")
        else:
            neg_keep = int(len(pos_samples) * self.neg_per_pos)
            if neg_keep <= 0:
                kept = pos_samples
            else:
                if neg_keep >= len(neg_samples):
                    neg_kept = neg_samples
                else:
                    idx = self.rng.choice(len(neg_samples), size=neg_keep, replace=False)
                    neg_kept = [neg_samples[i] for i in idx]
                kept = pos_samples + neg_kept
        logger.info(f"Filtered: pos={len(pos_samples)}, neg_kept={len(kept)-len(pos_samples)} (neg_per_pos={self.neg_per_pos})")
        return kept
    
    def __len__(self) -> int:
        return len(self.indices)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        s = self.samples[self.indices[idx]]
        
        with rasterio.open(s['raw']) as src:
            bands = self.bands if max(self.bands) <= src.count else list(range(1, src.count + 1))
            image = src.read(bands).astype(np.float32)
        
        with rasterio.open(s['label']) as src:
            label = src.read(1)
        label = self._binarize_label(label)
        
        # å½’ä¸€åŒ–
        image = self._normalize(image)
        
        # æ•°æ®å¢å¼º
        if self.mode == 'train':
            image, label = self._augment(image, label)
        
        return torch.from_numpy(image).float(), torch.from_numpy(label.astype(np.int64))

    @staticmethod
    def _binarize_label(label: np.ndarray) -> np.ndarray:
        return (label > 0).astype(np.uint8)
    
    def _normalize(self, image: np.ndarray) -> np.ndarray:
        """å…¨å±€å½’ä¸€åŒ– - ä¿ç•™å…‰è°±å…³ç³»"""
        if self.use_global_norm:
            for i in range(image.shape[0]):
                stats = self.band_stats[i]
                p1, p99 = stats['p1'], stats['p99']
                # ç™¾åˆ†ä½æ•°è£å‰ª + å½’ä¸€åŒ–
                band = np.clip(image[i], p1, p99)
                image[i] = (band - p1) / (p99 - p1 + 1e-8)
        else:
            # å›é€€åˆ°é€æ ·æœ¬å½’ä¸€åŒ–
            for i in range(image.shape[0]):
                b = image[i]
                if b.max() > b.min():
                    image[i] = (b - b.min()) / (b.max() - b.min())
        return np.clip(image, 0, 1)
    
    def _augment(self, img: np.ndarray, lbl: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """é¥æ„Ÿä¸“ç”¨æ•°æ®å¢å¼º"""
        C, H, W = img.shape
        
        # å‡ ä½•å˜æ¢
        if np.random.rand() > 0.5:
            img = np.flip(img, axis=2).copy()
            lbl = np.flip(lbl, axis=1).copy()
        
        if np.random.rand() > 0.5:
            img = np.flip(img, axis=1).copy()
            lbl = np.flip(lbl, axis=0).copy()
        
        if np.random.rand() > 0.5:
            k = np.random.randint(1, 4)
            img = np.rot90(img, k, axes=(1, 2)).copy()
            lbl = np.rot90(lbl, k).copy()
        
        # å…‰è°±å¢å¼ºï¼ˆé¥æ„Ÿä¸“ç”¨ï¼‰
        # éšæœºäº®åº¦è°ƒæ•´
        if np.random.rand() < 0.5:
            factor = 0.9 + 0.2 * np.random.rand()
            img = img * factor
        
        # é€šé“éšæœºdropoutï¼ˆæ¨¡æ‹Ÿäº‘å±‚/ä¼ æ„Ÿå™¨å·®å¼‚ï¼‰
        if np.random.rand() < 0.3 and C > 1:
            num_drop = np.random.randint(1, C)
            drop_channels = np.random.choice(C, num_drop, replace=False)
            for ch in drop_channels:
                img[ch] = img[ch] * 0.5  # éƒ¨åˆ†é®æŒ¡è€Œéå®Œå…¨ç½®é›¶
        
        # å…‰è°±æ··åˆï¼ˆMixup-likeï¼‰
        if np.random.rand() < 0.3:
            mix_ratio = 0.1 + 0.2 * np.random.rand()
            img = img * (1 - mix_ratio) + np.roll(img, shift=1, axis=0) * mix_ratio
        
        # ç©ºé—´å™ªå£°
        if np.random.rand() < 0.3:
            noise_type = np.random.choice(['gaussian', 'speckle'])
            if noise_type == 'gaussian':
                sigma = 0.005 + 0.015 * np.random.rand()
                noise = np.random.normal(0, sigma, img.shape)
            else:  # speckle - ä¹˜æ€§å™ªå£°ï¼Œæ¨¡æ‹ŸSAR/é¥æ„Ÿä¼ æ„Ÿå™¨å™ªå£°
                sigma = 0.01 + 0.03 * np.random.rand()
                noise = np.random.normal(0, sigma, img.shape)
                noise = img * noise
            img = img + noise.astype(np.float32)
        
        return np.clip(img, 0, 1), lbl


# ============================================================================
# å›°éš¾æ ·æœ¬æŒ–æ˜é‡‡æ ·å™¨
# ============================================================================

class HardMiningSampler:
    """
    å›°éš¾æ ·æœ¬æŒ–æ˜é‡‡æ ·å™¨
    - åŸºäºç«ç‚¹åƒç´ æ•°é‡åˆ†æ¡¶ï¼ˆå¤§ç«ç‚¹vså°ç«ç‚¹å¹³è¡¡ï¼‰
    - åŸºäºç±»åˆ«æ¯”ä¾‹åŠ æƒï¼ˆå¤„ç†æç«¯ä¸å¹³è¡¡ï¼‰
    """
    def __init__(self, samples: List[Dict], indices: np.ndarray, 
                 fg_ratio_bins: List[float] = [0.001, 0.01, 0.05]):
        self.samples = [samples[i] for i in indices]
        self.indices = indices
        
        # åŸºäºfg_ratioåˆ†æ¡¶
        self.weights = []
        for s in self.samples:
            fg_ratio = s.get('fg_ratio', 0)
            fg_count = s.get('fg_count', 0)
            
            # åŸºç¡€æƒé‡ï¼šå¹³è¡¡ç±»åˆ«
            if fg_ratio < 0.001:
                base_weight = 0.5  # æå°ç«ç‚¹é™ä½æƒé‡
            elif fg_ratio < 0.01:
                base_weight = 2.0  # å°ç«ç‚¹å¢å¼º
            elif fg_ratio < 0.05:
                base_weight = 1.5  # ä¸­ç­‰ç«ç‚¹
            else:
                base_weight = 1.0  # å¤§ç«ç‚¹
            
            # å›°éš¾ç¨‹åº¦è°ƒæ•´ï¼ˆåƒç´ æ•°é€‚ä¸­=æ›´éš¾å­¦ï¼‰
            if 50 < fg_count < 500:
                hard_weight = 1.5  # ä¸­ç­‰å¤§å°ç«ç‚¹æ˜¯å›°éš¾æ ·æœ¬
            else:
                hard_weight = 1.0
            
            self.weights.append(base_weight * hard_weight)
    
    def get_sampler(self, num_samples: Optional[int] = None):
        if num_samples is None:
            num_samples = len(self.weights)
        return WeightedRandomSampler(self.weights, num_samples, replacement=True)


# ============================================================================
# åŠ¨æ€é˜ˆå€¼æœç´¢
# ============================================================================

@torch.no_grad()
def find_best_threshold(model: nn.Module, loader: DataLoader, device: torch.Tensor,
                       thresholds: List[float] = None) -> Tuple[float, float]:
    """
    åœ¨éªŒè¯é›†ä¸Šæœç´¢æœ€ä¼˜é˜ˆå€¼
    è¿”å›: (best_threshold, best_f1)
    """
    if thresholds is None:
        thresholds = np.linspace(0.05, 0.95, 19).tolist()
    
    model.eval()
    all_probs = []
    all_targets = []
    
    for images, labels in loader:
        images = images.to(device)
        outputs, _ = model(images)  # å¿½ç•¥edgeè¾“å‡º
        probs = torch.sigmoid(outputs).squeeze(1)
        
        all_probs.append(probs.cpu())
        all_targets.append(labels)
    
    all_probs = torch.cat(all_probs, dim=0).flatten()
    all_targets = torch.cat(all_targets, dim=0).flatten()
    
    best_f1 = 0.0
    best_thresh = 0.5
    
    for thresh in thresholds:
        preds = (all_probs > thresh).long()
        gt = (all_targets > 0).long()
        tp = ((preds == 1) & (gt == 1)).sum().item()
        fp = ((preds == 1) & (gt == 0)).sum().item()
        fn = ((preds == 0) & (gt == 1)).sum().item()
        
        precision = tp / (tp + fp + 1e-8)
        recall = tp / (tp + fn + 1e-8)
        f1 = 2 * precision * recall / (precision + recall + 1e-8)
        
        if f1 > best_f1:
            best_f1 = f1
            best_thresh = thresh
    
    return best_thresh, best_f1 * 100


# ============================================================================
# è®­ç»ƒä¸éªŒè¯å‡½æ•°
# ============================================================================

def train_epoch_v2(model: nn.Module, loader: DataLoader, criterion: nn.Module,
                   optimizer: torch.optim.Optimizer, device: torch.Tensor,
                   scaler: GradScaler, use_amp: bool, max_grad_norm: float = 1.0,
                   accum_steps: int = 1) -> Tuple[float, float]:
    """è®­ç»ƒä¸€ä¸ªepochï¼ˆæ”¯æŒè¾¹ç¼˜è¾…åŠ©ç›‘ç£ï¼‰"""
    model.train()
    total_loss = 0.0
    tp = fp = fn = 0
    optimizer.zero_grad()
    
    for i, (images, labels) in enumerate(loader):
        images, labels = images.to(device), labels.to(device)
        
        with autocast(enabled=use_amp):
            seg_out, edge_out = model(images)
            
            # ä¸»åˆ†å‰²æŸå¤±
            seg_loss = criterion(seg_out, labels)
            
            # è¾¹ç¼˜è¾…åŠ©æŸå¤±ï¼ˆè¾¹ç¼˜ = ç«ç‚¹è¾¹ç•ŒåŒºåŸŸï¼‰
            # æ„é€ è¾¹ç¼˜æ ‡ç­¾ï¼šç«ç‚¹è†¨èƒ€ - ç«ç‚¹è…èš€
            from scipy.ndimage import binary_dilation, binary_erosion
            edge_labels = []
            for j in range(labels.size(0)):
                lbl = labels[j].cpu().numpy()
                if lbl.sum() > 0:
                    dilated = binary_dilation(lbl > 0, iterations=2)
                    eroded = binary_erosion(lbl > 0, iterations=1) if lbl.sum() > 10 else lbl > 0
                    edge = dilated ^ eroded
                else:
                    edge = np.zeros_like(lbl, dtype=bool)
                edge_labels.append(torch.from_numpy(edge).float())
            edge_label = torch.stack(edge_labels).to(device)
            
            edge_loss = F.binary_cross_entropy_with_logits(edge_out.squeeze(1), edge_label)
            
            # æ€»æŸå¤±
            loss = (seg_loss + 0.3 * edge_loss) / accum_steps
        
        if use_amp:
            scaler.scale(loss).backward()
        else:
            loss.backward()
        
        if (i + 1) % accum_steps == 0:
            if use_amp:
                scaler.unscale_(optimizer)
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
                scaler.step(optimizer)
                scaler.update()
            else:
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
                optimizer.step()
            optimizer.zero_grad()
        
        total_loss += loss.item() * accum_steps
        
        # è®¡ç®—æŒ‡æ ‡
        probs = torch.sigmoid(seg_out).squeeze(1)
        preds = (probs > 0.5).long()
        gt = (labels > 0).long()
        tp += ((preds == 1) & (gt == 1)).sum().item()
        fp += ((preds == 1) & (gt == 0)).sum().item()
        fn += ((preds == 0) & (gt == 1)).sum().item()
        
        if i % 10 == 0:
            p = tp / (tp + fp + 1e-8) * 100
            r = tp / (tp + fn + 1e-8) * 100
            f1 = 2 * p * r / (p + r + 1e-8)
            logger.info(f'  [{i}/{len(loader)}] Loss: {loss.item()*accum_steps:.4f} P:{p:.1f}% R:{r:.1f}% F1:{f1:.1f}%')
    
    avg_loss = total_loss / len(loader)
    precision = tp / (tp + fp + 1e-8) * 100
    recall = tp / (tp + fn + 1e-8) * 100
    f1 = 2 * precision * recall / (precision + recall + 1e-8)
    
    logger.info(f'Train - Loss: {avg_loss:.4f} P:{precision:.2f}% R:{recall:.2f}% F1:{f1:.2f}%')
    return avg_loss, f1


@torch.no_grad()
def validate_v2(model: nn.Module, loader: DataLoader, criterion: nn.Module,
                device: torch.Tensor, threshold: float = 0.5) -> Tuple[float, ...]:
    """éªŒè¯å‡½æ•°ï¼ˆæ”¯æŒåŠ¨æ€é˜ˆå€¼ï¼‰"""
    model.eval()
    total_loss = 0.0
    tp = fp = fn = tn = 0
    
    all_probs = []
    all_targets = []
    
    for images, labels in loader:
        images, labels = images.to(device), labels.to(device)
        seg_out, _ = model(images)
        
        loss = criterion(seg_out, labels)
        total_loss += loss.item()
        
        probs = torch.sigmoid(seg_out).squeeze(1)
        all_probs.append(probs.cpu())
        all_targets.append(labels.cpu())
        
        preds = (probs > threshold).long()
        gt = (labels > 0).long()
        tp += ((preds == 1) & (gt == 1)).sum().item()
        fp += ((preds == 1) & (gt == 0)).sum().item()
        fn += ((preds == 0) & (gt == 1)).sum().item()
        tn += ((preds == 0) & (labels == 0)).sum().item()
    
    avg_loss = total_loss / len(loader)
    precision = tp / (tp + fp + 1e-8) * 100
    recall = tp / (tp + fn + 1e-8) * 100
    f1 = 2 * precision * recall / (precision + recall + 1e-8)
    iou = tp / (tp + fp + fn + 1e-8) * 100
    
    # åŠ¨æ€é˜ˆå€¼æœç´¢
    all_probs = torch.cat([p.flatten() for p in all_probs])
    all_targets = torch.cat([t.flatten() for t in all_targets])
    
    best_thresh, best_f1_dynamic = 0.5, f1
    try:
        best_thresh, best_f1_dynamic = find_best_threshold(model, loader, device)
    except Exception as e:
        logger.warning(f"Threshold search failed: {e}")
    
    logger.info(f'Val - Loss: {avg_loss:.4f} F1:{f1:.2f}% IoU:{iou:.2f}% P:{precision:.2f}% R:{recall:.2f}%')
    logger.info(f'      Best thresh: {best_thresh:.2f} -> F1:{best_f1_dynamic:.2f}%')
    
    return avg_loss, f1, iou, precision, recall, best_thresh, best_f1_dynamic


# ============================================================================
# åˆ†å±‚å­¦ä¹ ç‡è°ƒåº¦å™¨
# ============================================================================

class LayerwiseWarmupScheduler:
    """
    åˆ†å±‚å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆä¿®å¤optimizeré‡å»ºé—®é¢˜ï¼‰
    - ä½¿ç”¨param_groupsè€Œéé‡å»ºoptimizer
    - æ”¯æŒä¸åŒé˜¶æ®µçš„åˆ†å±‚å­¦ä¹ ç‡
    """
    def __init__(self, optimizer: torch.optim.Optimizer, warmup_epochs: int,
                 total_epochs: int, base_lr: float, min_lr: float = 1e-7):
        self.optimizer = optimizer
        self.warmup_epochs = warmup_epochs
        self.total_epochs = total_epochs
        self.base_lr = base_lr
        self.min_lr = min_lr
        self.stage = 'warmup'  # warmup, normal
        
        # è®°å½•åˆå§‹å­¦ä¹ ç‡æ¯”ä¾‹
        self.lr_scales = []
        for group in optimizer.param_groups:
            self.lr_scales.append(group['lr'] / base_lr)
    
    def step(self, epoch: int, stage: str = None):
        """
        stage: 'warmup', 'normal', 'finetune'
        """
        if stage:
            self.stage = stage
        
        if epoch < self.warmup_epochs:
            # Warmupé˜¶æ®µ
            warmup_factor = (epoch + 1) / self.warmup_epochs
            for i, group in enumerate(self.optimizer.param_groups):
                lr = self.base_lr * self.lr_scales[i] * warmup_factor
                group['lr'] = lr
        else:
            # Cosineé€€ç«
            progress = (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)
            lr_factor = 0.5 * (1 + np.cos(np.pi * progress))
            lr_factor = max(lr_factor, self.min_lr / self.base_lr)
            
            for i, group in enumerate(self.optimizer.param_groups):
                lr = self.base_lr * self.lr_scales[i] * lr_factor
                group['lr'] = lr
        
        return [g['lr'] for g in self.optimizer.param_groups]


# ============================================================================
# å¯è§†åŒ–
# ============================================================================

def visualize_predictions_v2(model: nn.Module, loader: DataLoader, device: torch.Tensor,
                             num_samples: int = 4, save_dir: str = './visualizations',
                             threshold: float = 0.5):
    """å¯è§†åŒ–é¢„æµ‹ç»“æœï¼ˆåŒ…å«è¾¹ç¼˜ï¼‰"""
    os.makedirs(save_dir, exist_ok=True)
    model.eval()
    
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    
    count = 0
    for images, labels in loader:
        if count >= num_samples:
            break
        
        images = images.to(device)
        seg_out, edge_out = model(images)
        
        probs = torch.sigmoid(seg_out).squeeze(1)
        preds = (probs > threshold).long()
        edges = torch.sigmoid(edge_out).squeeze(1)
        
        for i in range(min(2, images.size(0))):
            if count >= num_samples:
                break
            
            fig, axes = plt.subplots(1, 5, figsize=(20, 4))
            
            # è¾“å…¥å›¾åƒ
            img = images[i].cpu().numpy()
            if img.shape[0] >= 3:
                rgb = np.stack([img[0], img[1], img[2]], axis=-1)
                axes[0].imshow(rgb)
            else:
                axes[0].imshow(img[0], cmap='gray')
            axes[0].set_title('Input')
            axes[0].axis('off')
            
            # æ ‡ç­¾
            axes[1].imshow(labels[i].cpu().numpy(), cmap='hot')
            axes[1].set_title('Ground Truth')
            axes[1].axis('off')
            
            # é¢„æµ‹æ¦‚ç‡
            axes[2].imshow(probs[i].cpu().numpy(), cmap='hot', vmin=0, vmax=1)
            axes[2].set_title('Pred Probability')
            axes[2].axis('off')
            
            # é¢„æµ‹ç»“æœ
            axes[3].imshow(preds[i].cpu().numpy(), cmap='hot')
            axes[3].set_title(f'Prediction (t={threshold:.2f})')
            axes[3].axis('off')
            
            # è¾¹ç¼˜é¢„æµ‹
            axes[4].imshow(edges[i].cpu().numpy(), cmap='hot', vmin=0, vmax=1)
            axes[4].set_title('Edge Prediction')
            axes[4].axis('off')
            
            plt.tight_layout()
            plt.savefig(f'{save_dir}/sample_{count}.png', dpi=150)
            plt.close()
            
            count += 1
    
    logger.info(f"Saved {count} visualizations to {save_dir}")


# ============================================================================
# Gitè‡ªåŠ¨æäº¤
# ============================================================================

def git_commit_auto(message: str):
    """è‡ªåŠ¨æäº¤ä»£ç å˜æ›´"""
    try:
        import subprocess
        result = subprocess.run(['git', 'status', '--porcelain'],
                              capture_output=True, text=True, cwd='/root/codes/fire0226/selfCodes')
        
        if result.stdout.strip():
            subprocess.run(['git', 'add', '-A'], cwd='/root/codes/fire0226/selfCodes', check=True)
            subprocess.run(['git', 'commit', '-m', message], cwd='/root/codes/fire0226/selfCodes', check=True)
            
            push_result = subprocess.run(['git', 'push', 'origin', 'main'],
                                        capture_output=True, text=True,
                                        cwd='/root/codes/fire0226/selfCodes')
            if push_result.returncode == 0:
                logger.info(f'âœ… Git synced: {message[:50]}...')
            else:
                logger.warning('âš ï¸ Git commit OK but push failed')
        else:
            logger.info('â„¹ï¸ No code changes to commit')
    except Exception as e:
        logger.warning(f'âš ï¸ Git auto-commit failed: {e}')


# ============================================================================
# Main
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description='Fire Detection Training V2 (Optimized)')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('region', type=str, help='Region name (e.g., Asia1)')
    parser.add_argument('--data-dir', type=str, default=DEFAULT_DATA_DIR)
    parser.add_argument('--output-dir', type=str, default=None)
    parser.add_argument('--tensorboard-dir', type=str, default=DEFAULT_TENSORBOARD_DIR)
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--bands', type=int, nargs='+', default=[5, 6, 7],
                       help='Bands to use (default: [5,6,7] - optimal for fire detection)')
    parser.add_argument('--min-fg-pixels', type=int, default=10)
    parser.add_argument('--neg-per-pos', type=float, default=0.5,
                       help='Keep negatives per positive (default: 0.5)')
    parser.add_argument('--no-global-norm', action='store_true',
                       help='Disable global normalization (use per-sample)')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model', type=str, default='mamba_vision_S')
    parser.add_argument('--pretrained', action='store_true', default=True)
    
    # æŸå¤±å‚æ•°
    parser.add_argument('--tversky-alpha', type=float, default=0.3,
                       help='Tversky alpha (FN penalty, lower=more recall)')
    parser.add_argument('--tversky-beta', type=float, default=0.7,
                       help='Tversky beta (FP penalty)')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--batch-size', type=int, default=8)
    parser.add_argument('--lr', type=float, default=1e-4)
    parser.add_argument('--backbone-lr-scale', type=float, default=0.1,
                       help='Backbone learning rate scale (default: 0.1)')
    parser.add_argument('--weight-decay', type=float, default=0.01)
    parser.add_argument('--max-grad-norm', type=float, default=1.0)
    parser.add_argument('--num-workers', type=int, default=4)
    parser.add_argument('--warmup-epochs', type=int, default=5)
    parser.add_argument('--accum-steps', type=int, default=1)
    
    # æ—©åœå‚æ•°
    parser.add_argument('--early-stop-patience', type=int, default=5)
    parser.add_argument('--early-stop-min-f1', type=float, default=85.0,
                       help='Minimum F1 target (raised to 85%)')
    
    # åŠ¨æ€é˜ˆå€¼
    parser.add_argument('--dynamic-threshold', action='store_true', default=True,
                       help='Use dynamic threshold search during validation')
    
    # å…¶ä»–
    parser.add_argument('--use-amp', action='store_true', default=True)
    parser.add_argument('--tensorboard', action='store_true', default=True)
    parser.add_argument('--visualize', action='store_true', default=False)
    parser.add_argument('--use-all-regions', action='store_true', default=False)
    
    args = parser.parse_args()
    
    # è®­ç»ƒå‰è‡ªåŠ¨æäº¤
    git_commit_auto(f"Pre-train V2: {args.region}, bands={args.bands}, lr={args.lr}")
    
    torch.manual_seed(42)
    np.random.seed(42)
    
    if args.output_dir is None:
        args.output_dir = os.path.join(DEFAULT_OUTPUT_DIR, args.region + '_v2')
    os.makedirs(args.output_dir, exist_ok=True)
    
    # TensorBoard
    writer = None
    if args.tensorboard:
        exp_name = f"fire_v2_{args.region}_{datetime.now().strftime('%m%d_%H%M')}"
        tb_dir = os.path.join(args.tensorboard_dir, exp_name)
        writer = SummaryWriter(tb_dir)
        logger.info(f'TensorBoard: {tb_dir}')
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f'Device: {device}')
    
    # æ•°æ®é›†
    if args.use_all_regions:
        regions = [d for d in os.listdir(args.data_dir) 
                  if os.path.isdir(os.path.join(args.data_dir, d)) and not d.endswith('output')]
        train_datasets = [FireDatasetV2(args.data_dir, r, args.bands, 'train',
                                       min_fg_pixels=args.min_fg_pixels,
                                       use_global_norm=not args.no_global_norm,
                                       neg_per_pos=args.neg_per_pos) for r in regions]
        val_datasets = [FireDatasetV2(args.data_dir, r, args.bands, 'val',
                                     min_fg_pixels=args.min_fg_pixels,
                                     use_global_norm=not args.no_global_norm,
                                     neg_per_pos=args.neg_per_pos) for r in regions]
        train_ds = torch.utils.data.ConcatDataset(train_datasets)
        val_ds = torch.utils.data.ConcatDataset(val_datasets)
        logger.info(f'Using all regions: {regions}')
    else:
        train_ds = FireDatasetV2(args.data_dir, args.region, args.bands, 'train',
                                min_fg_pixels=args.min_fg_pixels,
                                use_global_norm=not args.no_global_norm,
                                neg_per_pos=args.neg_per_pos)
        val_ds = FireDatasetV2(args.data_dir, args.region, args.bands, 'val',
                              min_fg_pixels=args.min_fg_pixels,
                              use_global_norm=not args.no_global_norm,
                              neg_per_pos=args.neg_per_pos)
    
    # å›°éš¾æ ·æœ¬æŒ–æ˜é‡‡æ ·å™¨
    sampler = None
    if isinstance(train_ds, torch.utils.data.ConcatDataset):
        # æš‚ä¸å®ç°ConcatDatasetçš„å›°éš¾é‡‡æ ·
        pass
    else:
        try:
            hard_sampler = HardMiningSampler(train_ds.samples, train_ds.indices)
            sampler = hard_sampler.get_sampler()
            logger.info('Using hard mining sampler')
        except Exception as e:
            logger.warning(f'Could not create hard sampler: {e}')
    
    if sampler is not None:
        train_loader = DataLoader(train_ds, batch_size=args.batch_size, sampler=sampler,
                                  num_workers=args.num_workers, pin_memory=True)
    else:
        train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True,
                                  num_workers=args.num_workers, pin_memory=True)
    
    val_loader = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False,
                           num_workers=args.num_workers, pin_memory=True)
    
    # æ¨¡å‹
    pretrained_path = os.path.join(DEFAULT_PRETRAIN_DIR, 'mambavision_small_1k.pth') if args.pretrained else None
    model = FireDetectionModelV2(args.model, 1, len(args.bands), args.pretrained, pretrained_path).to(device)
    logger.info(f'Params: {sum(p.numel() for p in model.parameters())/1e6:.2f}M')
    
    # æŸå¤±å‡½æ•°
    criterion = CombinedFireLoss(
        tversky_weight=1.0,
        boundary_weight=0.5,
        focal_weight=1.0,
        tversky_alpha=args.tversky_alpha,
        tversky_beta=args.tversky_beta
    )
    logger.info(f'Using Combined Loss: Tversky(Î±={args.tversky_alpha},Î²={args.tversky_beta}) + Boundary + Focal')
    
    # ä¼˜åŒ–å™¨ - åˆ†å±‚å­¦ä¹ ç‡ï¼ˆä¿®å¤schedulerå†²çªï¼‰
    param_groups = [
        {'params': model.backbone.parameters(), 'lr': args.lr * args.backbone_lr_scale, 'name': 'backbone'},
        {'params': model.decoder.parameters(), 'lr': args.lr, 'name': 'decoder'},
    ]
    optimizer = AdamW(param_groups, lr=args.lr, weight_decay=args.weight_decay)
    
    # åˆ†å±‚å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = LayerwiseWarmupScheduler(optimizer, args.warmup_epochs, args.epochs, args.lr)
    scaler = GradScaler() if args.use_amp else None
    
    # è®­ç»ƒçŠ¶æ€
    best_f1 = 0.0
    best_epoch = 0
    best_threshold = 0.5
    epochs_no_improve = 0
    
    logger.info(f'\n{"="*70}')
    logger.info(f'Starting Training V2: {args.region}')
    logger.info(f'Target: F1 >= 94% (B5+B6+B7 optimal bands)')
    logger.info(f'{"="*70}\n')
    
    for epoch in range(1, args.epochs + 1):
        # åŠ¨æ€è°ƒæ•´è®­ç»ƒé˜¶æ®µ
        if epoch <= args.warmup_epochs:
            stage = 'warmup'
        elif epoch <= 20:
            stage = 'normal'
        else:
            stage = 'finetune'
        
        lrs = scheduler.step(epoch - 1, stage)
        logger.info(f'\nEpoch {epoch}/{args.epochs} [{stage}] LRs: backbone={lrs[0]:.2e}, decoder={lrs[1]:.2e}')
        logger.info('-' * 70)
        
        # è®­ç»ƒ
        train_loss, train_f1 = train_epoch_v2(
            model, train_loader, criterion, optimizer, device,
            scaler, args.use_amp, args.max_grad_norm, args.accum_steps
        )
        
        # éªŒè¯
        val_loss, val_f1, val_iou, val_p, val_r, best_thresh, best_f1_dyn = validate_v2(
            model, val_loader, criterion, device, best_threshold
        )
        
        # ä½¿ç”¨åŠ¨æ€é˜ˆå€¼ä½œä¸ºæœ€ä½³F1
        effective_f1 = best_f1_dyn if args.dynamic_threshold else val_f1
        
        # TensorBoard
        if writer:
            writer.add_scalar('Loss/train', train_loss, epoch)
            writer.add_scalar('Loss/val', val_loss, epoch)
            writer.add_scalar('Metrics/F1', val_f1, epoch)
            writer.add_scalar('Metrics/F1_dynamic', best_f1_dyn, epoch)
            writer.add_scalar('Metrics/IoU', val_iou, epoch)
            writer.add_scalar('Metrics/Precision', val_p, epoch)
            writer.add_scalar('Metrics/Recall', val_r, epoch)
            writer.add_scalar('Threshold/best', best_thresh, epoch)
            writer.add_scalar('Train/lr_backbone', lrs[0], epoch)
            writer.add_scalar('Train/lr_decoder', lrs[1], epoch)
        
        # æ›´æ–°æœ€ä½³é˜ˆå€¼
        if best_f1_dyn > best_f1:
            best_threshold = best_thresh
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if effective_f1 > best_f1:
            best_f1 = effective_f1
            best_epoch = epoch
            epochs_no_improve = 0
            torch.save({
                'epoch': epoch,
                'model': model.state_dict(),
                'f1': effective_f1,
                'iou': val_iou,
                'p': val_p,
                'r': val_r,
                'threshold': best_threshold,
                'args': vars(args)
            }, os.path.join(args.output_dir, 'best_model.pth'))
            logger.info(f'âœ“ Saved best model (F1: {best_f1:.2f}%, thresh: {best_threshold:.2f})')
        else:
            epochs_no_improve += 1
            logger.info(f'  No F1 improvement for {epochs_no_improve} epochs')
        
        # æ—©åœ
        if epochs_no_improve >= args.early_stop_patience:
            logger.warning(f'\nğŸ›‘ Early stopping! No improvement for {args.early_stop_patience} epochs')
            logger.warning(f'   Best F1: {best_f1:.2f}% at epoch {best_epoch}')
            
            if best_f1 < args.early_stop_min_f1:
                logger.warning(f'   âš ï¸ Warning: Best F1 {best_f1:.2f}% < {args.early_stop_min_f1}% target')
            break
    
    # å¯è§†åŒ–
    if args.visualize:
        visualize_predictions_v2(model, val_loader, device, threshold=best_threshold)
    
    logger.info(f'\n{"="*70}')
    logger.info(f'ğŸ† Final Results:')
    logger.info(f'   Best F1: {best_f1:.2f}% @ epoch {best_epoch}')
    logger.info(f'   Best Threshold: {best_threshold:.2f}')
    logger.info(f'   Target: 94%+ (B5+B6+B7 bands)')
    logger.info(f'{"="*70}')
    
    # è®­ç»ƒåè‡ªåŠ¨æäº¤
    git_commit_auto(f"Post-train V2: {args.region} best F1={best_f1:.2f}% @ epoch {best_epoch}")
    
    if writer:
        writer.close()


if __name__ == '__main__':
    main()
